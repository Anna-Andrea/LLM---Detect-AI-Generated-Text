{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7425137,"sourceType":"datasetVersion","datasetId":4128386}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-18T10:57:45.786229Z","iopub.execute_input":"2024-01-18T10:57:45.786588Z","iopub.status.idle":"2024-01-18T10:57:45.812380Z","shell.execute_reply.started":"2024-01-18T10:57:45.786561Z","shell.execute_reply":"2024-01-18T10:57:45.811505Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/input/llm-aigenerated/train_v2_drcat_02.csv\n/kaggle/input/llm-aigenerated/llm-detect-ai-generated-text/sample_submission.csv\n/kaggle/input/llm-aigenerated/llm-detect-ai-generated-text/train_prompts.csv\n/kaggle/input/llm-aigenerated/llm-detect-ai-generated-text/test_essays.csv\n/kaggle/input/llm-aigenerated/llm-detect-ai-generated-text/train_essays.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# load data\ntrain_data = pd.read_csv('/kaggle/input/llm-aigenerated/llm-detect-ai-generated-text/train_essays.csv')\ntest_data = pd.read_csv('/kaggle/input/llm-aigenerated/llm-detect-ai-generated-text/test_essays.csv')\nex_data = pd.read_csv('/kaggle/input/llm-aigenerated/train_v2_drcat_02.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-18T12:41:42.330359Z","iopub.execute_input":"2024-01-18T12:41:42.330865Z","iopub.status.idle":"2024-01-18T12:41:43.371734Z","shell.execute_reply.started":"2024-01-18T12:41:42.330827Z","shell.execute_reply":"2024-01-18T12:41:43.370673Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# 为解决数据不平衡问题，合并train_data和ex_data\n# rename ex_data\nex_data.rename(columns={'label':'generated'}, inplace = True)\n# 截取train_data和ex_data的text, generated列\nselect_columns = ['text','generated']\ntrain_data_2 = train_data[select_columns]\nex_data_2 = ex_data[select_columns]\n# 垂直合并train_data & ex_data\ntrain_data_2 = pd.concat([train_data_2,ex_data_2],axis=0)\nprint(train_data_2)\nprint(train_data_2['generated'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-01-18T12:41:45.593227Z","iopub.execute_input":"2024-01-18T12:41:45.594155Z","iopub.status.idle":"2024-01-18T12:41:45.610731Z","shell.execute_reply.started":"2024-01-18T12:41:45.594109Z","shell.execute_reply":"2024-01-18T12:41:45.609716Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"                                                    text  generated\n0      Cars. Cars have been around since they became ...          0\n1      Transportation is a large necessity in most co...          0\n2      \"America's love affair with it's vehicles seem...          0\n3      How often do you ride in a car? Do you drive a...          0\n4      Cars are a wonderful thing. They are perhaps o...          0\n...                                                  ...        ...\n44863  Dear Senator,\\n\\nI am writing to you today to ...          1\n44864  Dear Senator,\\n\\nI am writing to you today to ...          1\n44865  Dear Senator,\\n\\nI am writing to you today to ...          1\n44866  Dear Senator,\\n\\nI am writing to you today to ...          1\n44867  Dear Senator,\\n\\nI am writing to you today to ...          1\n\n[46246 rows x 2 columns]\ngenerated\n0    28746\n1    17500\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"train_X = train_data_2['text']\ntrain_Y = train_data_2['generated']\nprint(train_X)\nprint(train_Y)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:45:47.217566Z","iopub.execute_input":"2024-01-18T11:45:47.217960Z","iopub.status.idle":"2024-01-18T11:45:47.225930Z","shell.execute_reply.started":"2024-01-18T11:45:47.217927Z","shell.execute_reply":"2024-01-18T11:45:47.224944Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"0        Cars. Cars have been around since they became ...\n1        Transportation is a large necessity in most co...\n2        \"America's love affair with it's vehicles seem...\n3        How often do you ride in a car? Do you drive a...\n4        Cars are a wonderful thing. They are perhaps o...\n                               ...                        \n44863    Dear Senator,\\n\\nI am writing to you today to ...\n44864    Dear Senator,\\n\\nI am writing to you today to ...\n44865    Dear Senator,\\n\\nI am writing to you today to ...\n44866    Dear Senator,\\n\\nI am writing to you today to ...\n44867    Dear Senator,\\n\\nI am writing to you today to ...\nName: text, Length: 46246, dtype: object\n0        0\n1        0\n2        0\n3        0\n4        0\n        ..\n44863    1\n44864    1\n44865    1\n44866    1\n44867    1\nName: generated, Length: 46246, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# 特征表示（向量表示）\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nfrom sklearn import model_selection","metadata":{"execution":{"iopub.status.busy":"2024-01-18T12:10:11.657198Z","iopub.execute_input":"2024-01-18T12:10:11.658073Z","iopub.status.idle":"2024-01-18T12:10:11.662779Z","shell.execute_reply.started":"2024-01-18T12:10:11.658036Z","shell.execute_reply":"2024-01-18T12:10:11.661759Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# 创建TfidfVectorizer对象\n# 设置词汇表大小为10000（可修改参数）\nvectorizer = TfidfVectorizer(max_features = 10000)\n# 将文本转换为TF-IDF向量表示\ntrain_Xtf = vectorizer.fit_transform(train_X)\n# 将TF-IDF向量表示和类别值转换为numpy数组\ntrain_Xtf = train_Xtf.toarray()\ntrain_Y = np.array(train_Y)\nprint(train_Xtf)\nprint(train_Xtf.shape)\nprint(train_Y)\nprint(train_Y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:57:38.756811Z","iopub.execute_input":"2024-01-18T11:57:38.757276Z","iopub.status.idle":"2024-01-18T11:58:01.178733Z","shell.execute_reply.started":"2024-01-18T11:57:38.757241Z","shell.execute_reply":"2024-01-18T11:58:01.177618Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n(46246, 10000)\n[0 0 0 ... 1 1 1]\n(46246,)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(np.count_nonzero(train_Xtf))\nprint(vectorizer.vocabulary_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 定义文本分类模型\ndef create_model(input_dim, output_dim):\n    model = keras.Sequential()\n    model.add(layers.Embedding(input_dim=input_dim, output_dim=64))\n    model.add(layers.Conv1D(128, 5, activation='relu'))\n    model.add(layers.GlobalMaxPooling1D())\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(output_dim, activation='softmax'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:52:34.910673Z","iopub.execute_input":"2024-01-18T11:52:34.911097Z","iopub.status.idle":"2024-01-18T11:52:34.917517Z","shell.execute_reply.started":"2024-01-18T11:52:34.911064Z","shell.execute_reply":"2024-01-18T11:52:34.916575Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# split train data for validation\nx_train, x_valid, y_train, y_valid = model_selection.train_test_split(train_Xtf, train_Y,\ntrain_size=0.80, test_size=0.20, random_state=4487)\ninput_dim = 10000 # 词汇表大小为10000，即输入维度为10000\noutput_dim = 2  # 二分类问题\n\n# 对文本序列进行填充，使其长度一致：压缩无效的填充值 0\nmax_length = 1000  # 假设最大序列长度为200\nx_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_length)\nx_valid = keras.preprocessing.sequence.pad_sequences(x_valid, maxlen=max_length)\n\n# 创建模型\nmodel = create_model(input_dim=input_dim, output_dim=output_dim)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-18T12:18:24.111618Z","iopub.execute_input":"2024-01-18T12:18:24.112533Z","iopub.status.idle":"2024-01-18T12:18:25.588815Z","shell.execute_reply.started":"2024-01-18T12:18:24.112501Z","shell.execute_reply":"2024-01-18T12:18:25.587970Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# 训练模型\nmodel.fit(x_train, y_train, batch_size=64, epochs=5, validation_data=(x_valid, y_valid))","metadata":{"execution":{"iopub.status.busy":"2024-01-18T12:18:27.873270Z","iopub.execute_input":"2024-01-18T12:18:27.873661Z","iopub.status.idle":"2024-01-18T12:19:50.637971Z","shell.execute_reply.started":"2024-01-18T12:18:27.873629Z","shell.execute_reply":"2024-01-18T12:19:50.636943Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Epoch 1/5\n579/579 [==============================] - 13s 19ms/step - loss: 0.6649 - accuracy: 0.6207 - val_loss: 0.6614 - val_accuracy: 0.6253\nEpoch 2/5\n579/579 [==============================] - 10s 17ms/step - loss: 0.6644 - accuracy: 0.6207 - val_loss: 0.6615 - val_accuracy: 0.6253\nEpoch 3/5\n579/579 [==============================] - 10s 18ms/step - loss: 0.6641 - accuracy: 0.6207 - val_loss: 0.6614 - val_accuracy: 0.6253\nEpoch 4/5\n579/579 [==============================] - 10s 18ms/step - loss: 0.6640 - accuracy: 0.6207 - val_loss: 0.6617 - val_accuracy: 0.6253\nEpoch 5/5\n579/579 [==============================] - 10s 17ms/step - loss: 0.6640 - accuracy: 0.6207 - val_loss: 0.6615 - val_accuracy: 0.6253\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7e8449f34130>"},"metadata":{}}]},{"cell_type":"code","source":"# predit \ntest_Xtf = vectorizer.fit_transform(test_data['text'])\ntest_Xtf = test_Xtf.toarray()\nprint(test_Xtf)\npredY = model.predict(test_Xtf)\nprint(predY)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T12:23:03.098212Z","iopub.execute_input":"2024-01-18T12:23:03.098946Z","iopub.status.idle":"2024-01-18T12:23:03.164707Z","shell.execute_reply.started":"2024-01-18T12:23:03.098913Z","shell.execute_reply":"2024-01-18T12:23:03.163778Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"[[0.72033345 0.54783215 0.42544054 0.         0.        ]\n [0.         0.61980538 0.48133417 0.61980538 0.        ]\n [0.         0.         0.42544054 0.54783215 0.72033345]]\n1/1 [==============================] - 0s 19ms/step\n[[0.6317123  0.36828765]\n [0.6317123  0.36828765]\n [0.6317123  0.36828765]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# write to csv\n# 数组转化为数据帧\npredY_df = pd.DataFrame(predY)\nprint(predY_df)\npd.DataFrame({'id':test_data['id'], 'generated':predY_df[1]}).to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T12:25:51.662663Z","iopub.execute_input":"2024-01-18T12:25:51.663051Z","iopub.status.idle":"2024-01-18T12:25:51.675143Z","shell.execute_reply.started":"2024-01-18T12:25:51.663019Z","shell.execute_reply":"2024-01-18T12:25:51.674067Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"          0         1\n0  0.631712  0.368288\n1  0.631712  0.368288\n2  0.631712  0.368288\n","output_type":"stream"}]}]}